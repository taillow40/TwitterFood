{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                     timestamp     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('LabeledTweets.csv', names=['sentiment', 'id', 'timestamp', 'query', 'user', 'text'])\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\taillow40\\AppData\\Local\\Temp\\ipykernel_220572\\2039518796.py:1: DtypeWarning: Columns (2,3,4,6,9,12,16,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  foods = pd.read_csv(\"../FoodData/branded_food.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fdc_id</th>\n",
       "      <th>brand_owner</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>subbrand_name</th>\n",
       "      <th>gtin_upc</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>not_a_significant_source_of</th>\n",
       "      <th>serving_size</th>\n",
       "      <th>serving_size_unit</th>\n",
       "      <th>household_serving_fulltext</th>\n",
       "      <th>branded_food_category</th>\n",
       "      <th>data_source</th>\n",
       "      <th>package_weight</th>\n",
       "      <th>modified_date</th>\n",
       "      <th>available_date</th>\n",
       "      <th>market_country</th>\n",
       "      <th>discontinued_date</th>\n",
       "      <th>preparation_state_code</th>\n",
       "      <th>trade_channel</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1105904</td>\n",
       "      <td>Richardson Oilseed Products (US) Limited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27000612323</td>\n",
       "      <td>Vegetable Oil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Oils Edible</td>\n",
       "      <td>GDSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1105905</td>\n",
       "      <td>CAMPBELL SOUP COMPANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51000198808</td>\n",
       "      <td>INGREDIENTS: BEEF STOCK, CONTAINS LESS THAN 2%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Herbs/Spices/Extracts</td>\n",
       "      <td>GDSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1105906</td>\n",
       "      <td>CAMPBELL SOUP COMPANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51000213273</td>\n",
       "      <td>INGREDIENTS: CLAM STOCK, POTATOES, CLAMS, CREA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.0</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prepared Soups</td>\n",
       "      <td>GDSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1105907</td>\n",
       "      <td>CAMPBELL SOUP COMPANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51000213303</td>\n",
       "      <td>INGREDIENTS: WATER, CREAM, BROCCOLI, CELERY, V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.0</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Prepared Soups</td>\n",
       "      <td>GDSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105908</td>\n",
       "      <td>CAMPBELL SOUP COMPANY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51000224637</td>\n",
       "      <td>INGREDIENTS: CHICKEN STOCK, CONTAINS LESS THAN...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>240.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Herbs/Spices/Extracts</td>\n",
       "      <td>GDSN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-10-03</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fdc_id                               brand_owner brand_name subbrand_name  \\\n",
       "0  1105904  Richardson Oilseed Products (US) Limited        NaN           NaN   \n",
       "1  1105905                     CAMPBELL SOUP COMPANY        NaN           NaN   \n",
       "2  1105906                     CAMPBELL SOUP COMPANY        NaN           NaN   \n",
       "3  1105907                     CAMPBELL SOUP COMPANY        NaN           NaN   \n",
       "4  1105908                     CAMPBELL SOUP COMPANY        NaN           NaN   \n",
       "\n",
       "      gtin_upc                                        ingredients  \\\n",
       "0  27000612323                                      Vegetable Oil   \n",
       "1  51000198808  INGREDIENTS: BEEF STOCK, CONTAINS LESS THAN 2%...   \n",
       "2  51000213273  INGREDIENTS: CLAM STOCK, POTATOES, CLAMS, CREA...   \n",
       "3  51000213303  INGREDIENTS: WATER, CREAM, BROCCOLI, CELERY, V...   \n",
       "4  51000224637  INGREDIENTS: CHICKEN STOCK, CONTAINS LESS THAN...   \n",
       "\n",
       "  not_a_significant_source_of  serving_size serving_size_unit  \\\n",
       "0                         NaN          15.0                ml   \n",
       "1                         NaN         240.0                ml   \n",
       "2                         NaN         440.0                 g   \n",
       "3                         NaN         440.0                 g   \n",
       "4                         NaN         240.0                ml   \n",
       "\n",
       "  household_serving_fulltext  branded_food_category data_source  \\\n",
       "0                        NaN            Oils Edible        GDSN   \n",
       "1                        NaN  Herbs/Spices/Extracts        GDSN   \n",
       "2                        NaN         Prepared Soups        GDSN   \n",
       "3                        NaN         Prepared Soups        GDSN   \n",
       "4                        NaN  Herbs/Spices/Extracts        GDSN   \n",
       "\n",
       "  package_weight modified_date available_date market_country  \\\n",
       "0            NaN    2020-10-02     2020-11-13  United States   \n",
       "1            NaN    2020-09-12     2020-11-13  United States   \n",
       "2            NaN    2020-09-01     2020-11-13  United States   \n",
       "3            NaN    2020-09-01     2020-11-13  United States   \n",
       "4            NaN    2020-10-03     2020-11-13  United States   \n",
       "\n",
       "  discontinued_date preparation_state_code trade_channel short_description  \n",
       "0               NaN                    NaN           NaN               NaN  \n",
       "1               NaN                    NaN           NaN               NaN  \n",
       "2               NaN                    NaN           NaN               NaN  \n",
       "3               NaN                    NaN           NaN               NaN  \n",
       "4               NaN                    NaN           NaN               NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Initialize tools\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def preprocess_tweet(tweet):\n",
    "    oldTweet = tweet\n",
    "    # 1. Remove non-alphanumeric characters\n",
    "    tweet = re.sub(r\"[^a-zA-Z0-9\\s']\", \"\", tweet) \n",
    "\n",
    "    # 2. Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # 3. Expand contractions\n",
    "    contractions = {\n",
    "        \"isn't\": \"is not\", \"aren't\": \"are not\", \"wasn't\": \"was not\", \"weren't\": \"were not\",\n",
    "        \"can't\": \"cannot\", \"couldn't\": \"could not\", \"shouldn't\": \"should not\", \"won't\": \"will not\",\n",
    "        \"wouldn't\": \"would not\", \"didn't\": \"did not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "        \"doesn't\": \"does not\", \"don't\": \"do not\", \"i'm\": \"i am\", \"it's\": \"it is\", \"you're\": \"you are\",\n",
    "        \"they're\": \"they are\", \"we're\": \"we are\", \"i've\": \"i have\", \"you've\": \"you have\"\n",
    "    }\n",
    "    for contraction, expanded in contractions.items():\n",
    "        tweet = tweet.replace(contraction, expanded)\n",
    "    tweet = re.sub(r\"[']\", \"\", tweet)\n",
    "\n",
    "    # 4. Handle negations\n",
    "    words = tweet.split(\" \")\n",
    "    processed_words = []\n",
    "    negate = False\n",
    "    for word in words:\n",
    "        if word in [\"not\", \"no\", \"never\"]:\n",
    "            negate = True\n",
    "        elif negate and word not in stop_words:\n",
    "            processed_words.append(f\"not_{word}\")\n",
    "            negate = False\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "\n",
    "    # 5. Remove stopwords\n",
    "    filtered_words = [word for word in processed_words if word not in stop_words]\n",
    "\n",
    "    # 6. Lemmatize words\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
    "    new_tweet = \" \".join(lemmatized_words)\n",
    "    new_tweet = re.sub(r'\\s+', ' ', new_tweet)\n",
    "    return new_tweet\n",
    "\n",
    "# Preprocess the dataset\n",
    "processed_tweets = [preprocess_tweet(tweet) for tweet in tweets['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flakes', 'enriched', 'alfredo', 'pomegranates', 'meatballs', 'fava', 'marmalades', 'sake', 'knackwurst', 'throttle', 'parsley', 'pearl', 'krispies', 'oranges', 'crumbled', 'tso', 'muffin', 'ramen', 'loaf', 'ostrich', 'bartlett', 'cranberry', 'semisoft', 'patties', 'kiwifruit', 'cookies', 'granola', 'asparagus', 'stews', 'falafel', 'shank', 'soyburgers', 'alcoholic', 'veal', 'mayo', 'ice', 'raisins', 'herbal', 'onions', 'roasted', 'similac', 'clam', 'recipes', 'rabbit', 'egg', 'turkey', 'creme', 'crayfish', 'seco', 'chard', 'marmalade', 'mackerel', 'grease', 'pudding', 'condiments', 'unsalted', 'oils', 'nachos', 'sorbitol', 'italian', 'creamed', 'reconstituted', 'mortadella', 'agave', 'papaya', 'orange', 'caesar', 'acai', 'prepackaged', 'evaporated', 'laver', 'coriander', 'treats', 'alcohol', 'fresco', 'flaked', 'crisps', 'feta', 'snapper', 'caramel', 'mushrooms', 'curry', 'lard', 'doughnut', 'peas', 'shake', 'payday', 'aloe', 'marinara', 'waffle', 'roma', 'sticks', 'spinach', 'flavored', 'dehydrated', 'provolone', 'pan', 'yeast', 'chewy', 'macadamia', 'chinook', 'crab', 'coating', 'canola', 'scalloped', 'starfruit', 'pickle', 'fondant', 'gruyere', 'noodle', 'cranberries', 'pomegranate', 'kielbasa', 'grapefruit', 'chocolate', 'salsa', 'substitute', 'pepsico', 'zucchini', 'anchovy', 'chili', 'soymilk', 'masa', 'confectioners', 'croissants', 'cracker', 'nigari', 'litchis', 'blueberry', 'tonic', 'eggs', 'shrimp', 'leavening', 'milkfat', 'incomplete', 'brewed', 'sloppy', 'precooked', 'cream', 'coffee', 'burgers', 'cocktail', 'giblets', 'cubes', 'oaxaca', 'drippings', 'miso', 'sugarless', 'edamame', 'mushroom', 'blueberries', 'cress', 'pollock', 'frozen', 'pears', 'lemon', 'naan', 'iceberg', 'eggnog', 'walnuts', 'tropical', 'bars', 'wafers', 'punch', 'melon', 'beer', 'olives', 'sage', 'cherry', 'gumdrops', 'meat', 'kaiser', 'grits', 'turnover', 'gluten', 'lesuer', 'cracklings', 'nugget', 'margarine', 'bamboo', 'spirulina', 'herb', 'moose', 'tiger', 'nopales', 'caramels', 'cocoa', 'honeycrisp', 'yambean', 'swordfish', 'macaroon', 'soybean', 'persimmons', 'pheasant', 'sliced', 'pike', 'roni', 'chow', 'apricots', 'kosher', 'granadilla', 'corned', 'broiled', 'pupusas', 'cauliflower', 'fructose', 'enfacare', 'abalone', 'applesauce', 'limes', 'jerky', 'pickled', 'hain', 'syrups', 'skinless', 'pizza', 'puerto', 'kat', 'crimini', 'thin', 'guava', 'microwave', 'peaches', 'loin', 'braunschweiger', 'prune', 'desserts', 'entrees', 'poultry', 'molasses', 'escarole', 'cervelat', 'tots', 'pimiento', 'portabella', 'jalapeno', 'tripe', 'bologna', 'sugar', 'nectar', 'halves', 'poached', 'honey', 'popcorn', 'snowpeas', 'savoy', 'formulated', 'biscotti', 'skins', 'quail', 'hummus', 'mandarin', 'minced', 'sundae', 'tallow', 'bagels', 'noor', 'entree', 'nutramigen', 'sulfate', 'carbonated', 'cornbread', 'spaghetti', 'stewed', 'soybeans', 'chicken', 'dough', 'sole', 'juice', 'tomatoes', 'puff', 'virgin', 'enchilada', 'pumpkin', 'taffy', 'eclair', 'pot', 'poke', 'dulce', 'breast', 'shortribs', 'singles', 'puffed', 'frog', 'confection', 'soups', 'sandwich', 'muffins', 'dill', 'wheat', 'fontina', 'sea', 'hormel', 'potato', 'protect', 'guarana', 'cashew', 'taco', 'creamer', 'guavas', 'whitener', 'shiitake', 'coca', 'buckwheat', 'crunchies', 'hominy', 'burrito', 'leeks', 'cups', 'starch', 'mung', 'kelp', 'ovaltine', 'yogurt', 'eel', 'apple', 'parsnips', 'lobster', 'premium', 'lambsquarters', 'lowfat', 'cones', 'cookie', 'rainbow', 'paprika', 'mead', 'banana', 'heated', 'niacin', 'japanese', 'sherbet', 'fillet', 'catfish', 'bacon', 'granulated', 'dandelion', 'shell', 'thuringer', 'gingerbread', 'oats', 'gouda', 'seasoned', 'cumin', 'flounder', 'broilers', 'jicama', 'shoots', 'tamale', 'chives', 'plantains', 'bottled', 't', 'jam', 'collards', 'chorizo', 'strawberries', 'waxgourd', 'chop', 'neosure', 'safflower', 'gin', 'tangerines', 'custard', 'goose', 'nutri', 'paratha', 'beets', 'phyllo', 'toast', 'flour', 'pineapple', 'gravy', 'catsup', 'bean', 'danish', 'flavors', 'seedless', 'salami', 'scallop', 'cotija', 'whey', 'gordita', 'burdock', 'buns', 'scallions', 'enfagrow', 'tips', 'oolong', 'chuck', 'basil', 'rice', 'tartar', 'ranch', 'gourd', 'mozzarella', 'broadbeans', 'honeydew', 'cornstarch', 'figs', 'currants', 'ale', 'potassium', 'russet', 'bun', 'sodium', 'seafood', 'ravioli', 'turtle', 'plums', 'olive', 'milky', 'vienna', 'romaine', 'simmered', 'sourdough', 'marie', 'melts', 'bratwurst', 'plantain', 'turnips', 'ruth', 'berries', 'pine', 'propionate', 'smoothie', 'terra', 'reese', 'toasted', 'maple', 'fried', 'relish', 'supplement', 'pork', 'quinoa', 'powdered', 'broiler', 'stew', 'mayonnaise', 'butterfinger', 'rind', 'cod', 'sauce', 'chayote', 'cob', 'multigrain', 'raab', 'chamomile', 'kefir', 'kellogg', 'chewing', 'toppings', 'ham', 'ribeye', 'oleic', 'surimi', 'rum', 'flank', 'avocado', 'podded', 'mole', 'ribs', 'pao', 'dried', 'zante', 'crunch', 'hazelnuts', 'confectioner', 'soy', 'chews', 'chitterlings', 'lasagna', 'bites', 'brisket', 'pepperoni', 'glutinous', 'ginger', 'bouillon', 'edible', 'yellowfin', 'radishes', 'prosobee', 'biscuit', 'frosting', 'tea', 'vegetarian', 'leavened', 'scrapple', 'fruitcake', 'vitamin', 'kung', 'seaweed', 'pods', 'bbq', 'biscuits', 'pressed', 'leafy', 'than', 'microwaved', 'groats', 'glazed', 'unilever', 'buttermilk', 'browned', 'pumpernickel', 'broccoli', 'cornish', 'corn', 'bake', 'cooked', 'lgg', 'boneless', 'pedialyte', 'strips', 'verde', 'pastrami', 'beans', 'perch', 'rican', 'bagel', 'pulp', 'pokeberry', 'arugula', 'pear', 'cantaloupe', 'pilaf', 'salisbury', 'filling', 'kidney', 'sugars', 'pretzels', 'sauces', 'kashi', 'oysters', 'chesnut', 'syrup', 'overripe', 'fruit', 'puramino', 'sesame', 'dessert', 'puffs', 'berry', 'bollilo', 'vegetables', 'powder', 'goat', 'fruits', 'foo', 'golean', 'strip', 'couscous', 'shortening', 'celery', 'nestle', 'marshmallow', 'fryers', 'spanish', 'cornmeal', 'cowpeas', 'pancake', 'steamed', 'malted', 'octopus', 'raspberries', 'fuji', 'tangerine', 'creams', 'naked', 'trout', 'mollusks', 'kernels', 'magnesium', 'sweetened', 'alimentum', 'manzanilla', 'potatoes', 'pak', 'dumpling', 'kale', 'dip', 'tzatziki', 'pie', 'chapati', 'fennel', 'leche', 'raisin', 'cupcake', 'crepe', 'hershey', 'crustaceans', 'chia', 'backribs', 'buttered', 'breading', 'poppy', 'strawberry', 'creamy', 'rolls', 'sucralose', 'novelties', 'watermelon', 'jellies', 'pacific', 'nonfat', 'squares', 'hollandaise', 'fritolay', 'creamsicle', 'pediasure', 'scrambled', 'fat', 'sockeye', 'cerdo', 'breadstick', 'caviar', 'vanilla', 'nacho', 'grilled', 'brazilnuts', 'wonton', 'opossum', 'coleslaw', 'milk', 'beverage', 'cottage', 'broth', 'gala', 'chips', 'porterhouse', 'shoulder', 'bran', 'pita', 'crunchy', 'macaroni', 'palm', 'water', 'beef', 'zwieback', 'seed', 'agar', 'legs', 'duck', 'refried', 'nut', 'cabbage', 'tortillas', 'cuts', 'doughnuts', 'salty', 'pasta', 'melba', 'batter', 'roll', 'linolenic', 'slice', 'neck', 'sausage', 'twix', 'drumstick', 'herring', 'ocean', 'skim', 'mars', 'oatmeal', 'watercress', 'snickers', 'bone', 'thiamin', 'sweetener', 'slimfast', 'caribou', 'cured', 'pound', 'bulgur', 'species', 'lima', 'preserves', 'cereal', 'congee', 'rutabagas', 'pecans', 'seeded', 'cider', 'sandwiches', 'rye', 'arrowroot', 'semisweet', 'radicchio', 'lifeway', 'mullet', 'wakame', 'par', 'parts', 'bones', 'dosa', 'protein', 'capers', 'pantothenic', 'skittles', 'dove', 'monterey', 'sweeteners', 'deli', 'marshmallows', 'pepper', 'brownies', 'haddock', 'papayas', 'seeds', 'croaker', 'hibiscus', 'sirloin', 'vermicelli', 'garlic', 'lipil', 'sour', 'braised', 'jams', 'nutmeg', 'caffeine', 'cone', 'thai', 'shoyu', 'maraschino', 'wafer', 'squid', 'thick', 'pastries', 'lo', 'spices', 'cassava', 'separable', 'snackfood', 'artichokes', 'popped', 'puddings', 'frostings', 'serrano', 'kids', 'beet', 'liqueur', 'carambola', 'restructured', 'imitation', 'kraft', 'blackberry', 'wasabi', 'wine', 'stuffed', 'filberts', 'crispy', 'nuts', 'breadfruit', 'bits', 'rings', 'croutons', 'coated', 'pregestimil', 'nutritional', 'quesadilla', 'waterchestnuts', 'roti', 'chickpeas', 'reheated', 'grape', 'horseradish', 'pinto', 'ensure', 'icing', 'snacks', 'foods', 'gizzard', 'sunflower', 'cheesecake', 'mirepoix', 'enfamil', 'peanuts', 'stuffing', 'fries', 'whipped', 'butters', 'puree', 'limburger', 'stock', 'mustard', 'carrot', 'tlc', 'microwaveable', 'tilapia', 'acid', 'fish', 'gum', 'steaks', 'omelet', 'tenders', 'waffles', 'jelly', 'smoked', 'focaccia', 'salt', 'fudgsicle', 'bass', 'dates', 'gingersnaps', 'sauerkraut', 'hotdog', 'hens', 'poppyseed', 'salted', 'mussel', 'thymus', 'guanabana', 'cheddar', 'fudge', 'millet', 'nuggets', 'choi', 'clams', 'bison', 'juices', 'butter', 'decaffeinated', 'spice', 'almond', 'hoisin', 'fig', 'oyster', 'rib', 'starburst', 'flaxseed', 'rhubarb', 'hazelnut', 'russian', 'oregano', 'citrus', 'papad', 'yolk', 'walnut', 'peanut', 'northern', 'pressurized', 'anejo', 'almonds', 'crowder', 'carnitas', 'thigh', 'pam', 'breaded', 'bread', 'baking', 'breadsticks', 'cinnamon', 'unsweetened', 'tortellini', 'sprite', 'spam', 'dressing', 'twists', 'taro', 'deer', 'pops', 'splenda', 'rotisserie', 'roasts', 'squash', 'dairy', 'turnip', 'cheeseburger', 'steak', 'diced', 'caraway', 'noodles', 'pate', 'pies', 'fajita', 'sardine', 'boiled', 'kohlrabi', 'pocket', 'snail', 'chops', 'angelfood', 'strained', 'rolled', 'blackeyes', 'baked', 'hersheys', 'mashed', 'scone', 'cereals', 'ripe', 'mexican', 'snack', 'pancakes', 'worcestershire', 'tamarinds', 'pearled', 'sope', 'cherries', 'chestnuts', 'patty', 'knockwurst', 'hush', 'straightneck', 'fry', 'lentils', 'sprouted', 'blackeyed', 'lentil', 'pakora', 'sprouts', 'coconut', 'avocados', 'frosted', 'cakes', 'pimento', 'thyme', 'roast', 'spray', 'lime', 'skirt', 'lemons', 'slices', 'tabasco', 'hamburger', 'canned', 'flatbread', 'garbanzo', 'muenster', 'tortilla', 'cayenne', 'tofu', 'hamburgers', 'sponge', 'sunchips', 'aspartame', 'cola', 'greens', 'chip', 'spareribs', 'phosphate', 'pickles', 'saltines', 'empanada', 'cheese', 'cornnuts', 'queso', 'prunes', 'shells', 'grapes', 'wing', 'okra', 'southern', 'lemonade', 'peppers', 'salsify', 'tenderloin', 'mein', 'grated', 'apricot', 'paste', 'tongue', 'swiss', 'matzo', 'ketchup', 'melons', 'hydrogenated', 'squab', 'barley', 'stevia', 'brussels', 'sulfured', 'pasteurized', 'kimchi', 'crumbles', 'canadian', 'raspberry', 'boar', 'peel', 'lactose', 'crookneck', 'topping', 'colby', 'curd', 'moist', 'salad', 'vegetable', 'onion', 'greek', 'pompano', 'roquefort', 'quaker', 'tuna', 'nutrients', 'ricotta', 'cacao', 'vitamins', 'pastry', 'graham', 'cilantro', 'cake', 'tomato', 'potsticker', 'desiccated', 'candies', 'flake', 'dipps', 'veggie', 'liver', 'oil', 'butterscotch', 'malt', 'vinegar', 'tapioca', 'grenadine', 'frijoles', 'fillets', 'oat', 'frankfurter', 'salmon', 'barbecue', 'peach', 'preformed', 'candy', 'vodka', 'root', 'carb', 'shark', 'cucumber', 'meatless', 'halibut', 'mounds', 'eggplant', 'crispbread', 'tub', 'bottles', 'nfs', 'folic', 'whiskey', 'kidneys', 'whiting', 'lamb', 'meal', 'saccharin', 'pistachio', 'brie', 'teriyaki', 'pretzel', 'shortbread', 'thousand', 'leg', 'powerade', 'seasoning', 'tart', 'yogurts', 'flatfish', 'kernel', 'meats', 'skin', 'wings', 'coatings', 'camembert', 'apples', 'turmeric', 'glaceau', 'spread', 'bananas', 'nougat', 'mangos', 'blackberries', 'soup', 'espresso', 'lettuce', 'puppies', 'mango', 'striped', 'soda', 'crackers', 'alfalfa', 'cran', 'carrots', 'browns', 'kumquats', 'deglet', 'nectarines', 'tops', 'parmesan', 'ascorbic', 'isomil', 'natto', 'guacamole', 'beverages'}\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()            \n",
    "    text = re.sub(r'\\d+', '', text) \n",
    "    text = re.sub(r'\\W+', ' ', text)    \n",
    "    return text.strip()\n",
    "\n",
    "foods = pd.read_csv(\"../FoodData/input_food.csv\")\n",
    "foods['sr_description'] = foods['sr_description'].apply(preprocess)\n",
    "words = set(word for desc in foods['sr_description'].dropna() for word in desc.split())\n",
    "\n",
    "# Remove common words from the set \n",
    "common_words = {\"the\", \"and\", \"no\", \"to\", \"be\", \"or\", \"a\", \"go\", \"year\", \"off\", \n",
    "                \"good\", \"up\", \"home\", \"mixed\", \"been\", \"great\", \"valley\", \n",
    "                \"choice\", \"red\", \"sun\", \"dog\", \"all\", \"of\", \"food\", \"with\", \"dark\", \"part\", \"for\", \"not\", \"w\", \"hard\", \"people\", \"as\", \"old\", \"like\", \"in\", \"fast\", \"butt\", \"only\", \"low\", \"white\", \"eat\", \"at\", \"hot\",\n",
    "                \"o\", \"s\", \"e\", \"b\", \"at\", \"on\", \"made\", \"pieces\", \"bowl\", \"drinking\", \"such\", \"stomach\", \"new\", \"have\", \"cut\", \"ready\", \"jack\", \"green\", \"yellow\", \"back\", \"snap\", \"dry\", \"brown\", \"way\", \"table\", \"replacement\", \"small\", \"high\", \"lil\", \"from\", \"may\", \"special\", \"summer\", \"next\", \"cam\", \"back\", \"acting\", \"active\", \"additional\", \"advance\", \"agents\", \"air\", \"aluminum\", \"approximately\", \"areas\", \"arm\", \"average\", \"balance\", \"basis\", \"blade\", \"boost\", \"brain\", \"charged\", \"classes\", \"club\", \"combos\", \"common\", \"company\", \"compressed\", \"contents\", \"cytosport\", \"denver\", \"diabetes\", \"diarrhea\", \"dogs\", \"eastern\", \"except\", \"expert\", \"family\", \"feed\", \"fiber\", \"flesh\", \"fluid\", \"fordhook\", \"form\", \"formed\", \"formula\", \"general\", \"greater\", \"group\", \"inside\", \"iron\", \"island\", \"machine\", \"mature\", \"method\", \"mild\", \"mineral\", \"minerals\", \"multi\", \"muscle\", \"municipal\", \"other\", \"paper\", \"performance\", \"previously\", \"prime\", \"processing\", \"product\", \"products\", \"program\", \"purpose\", \"regular\", \"removed\", \"restaurant\", \"revive\", \"sensitive\", \"single\", \"size\", \"slightly\", \"solution\", \"standard\", \"straight\", \"style\", \"type\", \"types\", \"typical\", \"ultra\", \"under\", \"use\", \"varieties\", \"variety\", \"wild\", \"without\", \"zone\", \"abbott\", \"added\", \"additives\", \"american\", \"amp\", \"animal\", \"any\", \"ar\", \"ara\", \"armenian\", \"artificial\", \"assorted\", \"babyfood\", \"beach\", \"bear\", \"beaver\", \"bird\", \"bitter\", \"black\", \"bleached\", \"block\", \"blood\", \"boxed\", \"bulk\", \"bull\", \"bunches\", \"by\", \"c\", \"ca\", \"calcium\", \"calorie\", \"can\", \"candied\", \"carton\", \"center\", \"chain\", \"channel\", \"child\", \"classic\", \"clif\", \"commercial\", \"commercially\", \"composite\", \"con\", \"containing\", \"contains\", \"cottonseed\", \"country\", \"cracked\", \"crude\", \"cultured\", \"d\", \"dha\", \"dietary\", \"dietetic\", \"distilled\", \"domesticated\", \"eas\", \"electrolyte\", \"end\", \"energy\", \"english\", \"equal\", \"european\", \"extra\", \"extract\", \"eye\", \"fashioned\", \"fed\", \"fine\", \"finger\", \"fluoride\", \"fortified\", \"free\", \"fresh\", \"full\", \"fully\", \"g\", \"game\", \"generic\", \"gentle\", \"genuine\", \"greater\", \"grow\", \"gummy\", \"half\", \"headcheese\", \"heart\", \"hearts\", \"higher\", \"household\", \"hydrated\", \"immature\", \"industrial\", \"infant\", \"instant\", \"iron\", \"isolate\", \"johnson\", \"junior\", \"kit\", \"king\", \"ladyfingers\", \"large\", \"latino\", \"leaf\", \"leather\", \"leaves\", \"less\", \"light\", \"lightly\", \"link\", \"links\", \"lip\", \"liquid\", \"liquids\", \"loaded\", \"lotus\", \"lower\", \"m\", \"maid\", \"mature\", \"menu\", \"method\", \"mild\", \"mills\", \"mini\", \"minute\", \"mixture\", \"moisture\", \"monster\", \"mum\", \"multi\", \"musketeers\", \"native\", \"natural\", \"nature\", \"navels\", \"non\", \"nos\", \"ns\", \"optima\", \"other\", \"pack\", \"packaged\", \"packet\", \"packets\", \"perfect\", \"performance\", \"plus\", \"pm\", \"portion\", \"purchased\", \"purpose\", \"reduced\", \"refrigerated\", \"removed\", \"restaurant\", \"retail\", \"retain\", \"rich\", \"rockstar\", \"rush\", \"schiff\", \"school\", \"alaska\", \"amber\", \"asian\", \"atlantic\", \"baby\", \"baker\", \"bakery\", \"base\", \"based\", \"bell\", \"bengal\", \"blend\", \"blended\", \"blends\", \"blue\", \"brick\", \"boston\", \"brittle\", \"bulb\", \"button\", \"care\", \"carp\", \"celestial\", \"cellophane\", \"chinese\", \"chloride\", \"cholesterol\", \"clod\", \"colored\", \"concentrate\", \"contain\", \"covered\", \"crumbs\", \"crust\", \"distribution\", \"double\", \"end\", \"expressed\", \"extruded\", \"farmed\", \"feet\", \"filled\", \"fillings\", \"flowers\", \"fortune\", \"gatorade\", \"generic\", \"gentlease\", \"gerber\", \"goddess\", \"gold\", \"graduates\", \"grain\", \"gram\", \"granular\", \"granules\", \"grass\", \"grecian\", \"greater\", \"group\", \"anhydrous\", \"balsam\", \"de\", \"decker\", \"decorticated\", \"defatted\", \"degermed\", \"del\", \"drained\", \"extruded\", \"gelatin\", \"germ\", \"grade\", \"grades\", \"neutral\", \"packed\", \"plan\", \"preserving\", \"sections\", \"solid\", \"solids\", \"stable\", \"stage\", \"tabletop\", \"tap\", \"total\", \"transitions\", \"trimmed\", \"unblanched\", \"unbleached\", \"uncoated\", \"uncooked\", \"uncreamed\", \"undiluted\", \"unenriched\", \"unheated\", \"unprepared\", \"unspecified\", \"unsugared\", \"vault\", \"zero\", \"start\", \"long\", \"dinner\", \"breakfast\", \"drink\", \"top\", \"usda\", \"vacuum\", \"flavor\", \"passion\", \"sweet\", \"whole\", \"lunch\", \"garden\", \"spring\", \"round\", \"bar\", \"south\", \"power\", \"marathon\", \"pink\", \"quick\", \"original\", \"rose\", \"simple\", \"medium\", \"joe\", \"delicious\", \"ground\", \"stick\", \"drop\", \"recipe\", \"process\", \"wrap\", \"pre\", \"includes\", \"semi\", \"mix\", \"proof\", \"shelf\", \"spit\", \"smooth\", \"slim\", \"lean\", \"toddler\", \"iced\", \"traditional\", \"serve\", \"prepared\", \"raw\", \"packaging\", \"nutrition\", \"ingredients\", \"stir\", \"plain\", \"ingredient\", \"cold\", \"short\", \"round\", \"french\", \"winter\", \"cooking\", \"diet\", \"florida\", \"pop\", \"heat\", \"bite\", \"purple\", \"trail\", \"include\", \"oven\", \"plate\", \"flat\", \"eaten\", \"split\", \"us\", \"pad\", \"squirrel\", \"heavy\", \"z\", \"smith\", \"granny\", \"raccoon\", \"picnic\", \"soft\", \"prop\", \"globe\", \"hash\", \"toaster\", \"sticker\", \"lite\", \"vera\", \"luncheon\", \"yung\", \"chopped\", \"condensed\"}\n",
    "\n",
    "words = words - common_words\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sorted(list(words))\n",
    "pd.DataFrame({'words': sorted_words}).to_csv('food_words.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets is a df with a column text that contains the tweets\n",
    "#words is a set of words\n",
    "#sort the tweets by the number of words in the tweet that are in the set words\n",
    "#print them, only the text column and how many of the words match in the format {words}:{text}\n",
    "def count_matching_words(text, words_set):\n",
    "    return sum(1 for word in text.split() if word in words_set)\n",
    "\n",
    "def highlight_matching_words(text, words_set):\n",
    "    return ' '.join([f\"{word}*\" if word in words_set else word for word in text.split()])\n",
    "\n",
    "output_counts = [count_matching_words(text, words) for text in processed_tweets]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a df of output_count and preprocessed_tweets\n",
    "#drop the rows with 0 output_count\n",
    "#save to csv\n",
    "data = {'output_count': output_counts, 'preprocessed_tweets': processed_tweets}\n",
    "df = pd.DataFrame(data)\n",
    "filtered_df = df[df['output_count'] != 0]\n",
    "filtered_df.to_csv('filtered_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
